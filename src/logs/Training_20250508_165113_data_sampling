Training started at: 2025-05-08 16:51:13

Transform for label 0:
 Compose([
  Resize(p=1.0, height=256, interpolation=1, mask_interpolation=0, width=256),
  Normalize(p=1.0, max_pixel_value=255.0, mean=(0.5, 0.5, 0.5), normalization='standard', std=(0.5, 0.5, 0.5)),
  ToTensorV2(p=1.0, transpose_mask=False),
], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}, is_check_shapes=True)

Transform for label 1:
 Compose([
  ShiftScaleRotate(p=0.5, shift_limit_x=(-0.05, 0.05), shift_limit_y=(-0.05, 0.05), scale_limit=(-0.050000000000000044, 0.050000000000000044), rotate_limit=(-5.0, 5.0), interpolation=1, border_mode=2, fill=0.0, fill_mask=0.0, rotate_method='largest_box', mask_interpolation=0),
  OneOf([
    CLAHE(p=0.3, clip_limit=(1.0, 2.0), tile_grid_size=(8, 8)),
    RandomBrightnessContrast(p=0.3, brightness_by_max=True, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), ensure_safe_range=False),
    HueSaturationValue(p=0.3, hue_shift_limit=(-20.0, 20.0), sat_shift_limit=(-30.0, 30.0), val_shift_limit=(-20.0, 20.0)),
  ], p=1.0),
  Resize(p=1.0, height=256, interpolation=1, mask_interpolation=0, width=256),
  Normalize(p=1.0, max_pixel_value=255.0, mean=(0.5, 0.5, 0.5), normalization='standard', std=(0.5, 0.5, 0.5)),
  ToTensorV2(p=1.0, transpose_mask=False),
], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}, is_check_shapes=True)
Class 0 count: 32542
Class 1 count: 584
[INFO] Starting augmentation. Total original samples: 26500
[INFO] Dataset type: <class 'torch.utils.data.dataset.Subset'>
Class 0 count: 26023
Class 1 count: 2862
Learning Rate      : 0.0001
Batch Size   : 32
Epochs : 30
Threashold : 0.5
Total Samples      : 35511
Training Samples   : 28885
Validation Samples : 3312
Testing Samples : 3314
Epoch [1/30], Step [50/903], Loss: 0.1731
Epoch [1/30], Step [100/903], Loss: 0.3221
Epoch [1/30], Step [150/903], Loss: 0.1066
Epoch [1/30], Step [200/903], Loss: 0.2076
Epoch [1/30], Step [250/903], Loss: 0.2228
Epoch [1/30], Step [300/903], Loss: 0.2897
Epoch [1/30], Step [350/903], Loss: 0.0843
Epoch [1/30], Step [400/903], Loss: 0.1175
Epoch [1/30], Step [450/903], Loss: 0.2485
Epoch [1/30], Step [500/903], Loss: 0.1701
Epoch [1/30], Step [550/903], Loss: 0.1138
Epoch [1/30], Step [600/903], Loss: 0.0886
Epoch [1/30], Step [650/903], Loss: 0.1109
Epoch [1/30], Step [700/903], Loss: 0.1004
Epoch [1/30], Step [750/903], Loss: 0.1187
Epoch [1/30], Step [800/903], Loss: 0.1241
Epoch [1/30], Step [850/903], Loss: 0.2228
Epoch [1/30], Step [900/903], Loss: 0.1622

Epoch [1/30] Summary:
Train Loss   : 0.1459
Train F1     : 0.6618
Train Recall : 0.7648
Train AUC    : 0.9494


Validation Evaluation:
Validation Loss   : 0.0893
Validation F1     : 0.1507
Validation Recall : 0.1964
Validation AUC    : 0.8736
[[3177   79]
 [  45   11]]
[INFO] Confusion matrix saved to: validation_confusion_matrix.png
Epoch [2/30], Step [50/903], Loss: 0.2011
Epoch [2/30], Step [100/903], Loss: 0.2034
Epoch [2/30], Step [150/903], Loss: 0.0502
Epoch [2/30], Step [200/903], Loss: 0.0622
Epoch [2/30], Step [250/903], Loss: 0.1201
Epoch [2/30], Step [300/903], Loss: 0.0636
Epoch [2/30], Step [350/903], Loss: 0.0608
Epoch [2/30], Step [400/903], Loss: 0.1100
Epoch [2/30], Step [450/903], Loss: 0.0131
Epoch [2/30], Step [500/903], Loss: 0.0968
Epoch [2/30], Step [550/903], Loss: 0.0756
Epoch [2/30], Step [600/903], Loss: 0.1120
Epoch [2/30], Step [650/903], Loss: 0.1298
Epoch [2/30], Step [700/903], Loss: 0.0279
Epoch [2/30], Step [750/903], Loss: 0.2319
Epoch [2/30], Step [800/903], Loss: 0.0402
Epoch [2/30], Step [850/903], Loss: 0.0243
Epoch [2/30], Step [900/903], Loss: 0.0503

Epoch [2/30] Summary:
Train Loss   : 0.0893
Train F1     : 0.8100
Train Recall : 0.8690
Train AUC    : 0.9807


Validation Evaluation:
Validation Loss   : 0.0771
Validation F1     : 0.1720
Validation Recall : 0.1429
Validation AUC    : 0.8968
[[3227   29]
 [  48    8]]
[INFO] Confusion matrix saved to: validation_confusion_matrix.png
Epoch [3/30], Step [50/903], Loss: 0.0410
Epoch [3/30], Step [100/903], Loss: 0.0274
Epoch [3/30], Step [150/903], Loss: 0.0367
Epoch [3/30], Step [200/903], Loss: 0.0609
Epoch [3/30], Step [250/903], Loss: 0.2493
Epoch [3/30], Step [300/903], Loss: 0.0381
Epoch [3/30], Step [350/903], Loss: 0.0379
Epoch [3/30], Step [400/903], Loss: 0.0684
Epoch [3/30], Step [450/903], Loss: 0.0287
Epoch [3/30], Step [500/903], Loss: 0.1179
Epoch [3/30], Step [550/903], Loss: 0.0698
Epoch [3/30], Step [600/903], Loss: 0.0370
Epoch [3/30], Step [650/903], Loss: 0.1232
Epoch [3/30], Step [700/903], Loss: 0.0701
Epoch [3/30], Step [750/903], Loss: 0.0127
Epoch [3/30], Step [800/903], Loss: 0.0253
Epoch [3/30], Step [850/903], Loss: 0.0184
Epoch [3/30], Step [900/903], Loss: 0.0733

Epoch [3/30] Summary:
Train Loss   : 0.0674
Train F1     : 0.8487
Train Recall : 0.8899
Train AUC    : 0.9894


Validation Evaluation:
Validation Loss   : 0.0956
Validation F1     : 0.2222
Validation Recall : 0.2679
Validation AUC    : 0.8719
[[3192   64]
 [  41   15]]
[INFO] Confusion matrix saved to: validation_confusion_matrix.png
Epoch [4/30], Step [50/903], Loss: 0.0391
Epoch [4/30], Step [100/903], Loss: 0.0422
Epoch [4/30], Step [150/903], Loss: 0.2070
Epoch [4/30], Step [200/903], Loss: 0.0147
Epoch [4/30], Step [250/903], Loss: 0.0193
Epoch [4/30], Step [300/903], Loss: 0.0053
Epoch [4/30], Step [350/903], Loss: 0.0163
Epoch [4/30], Step [400/903], Loss: 0.0537
Epoch [4/30], Step [450/903], Loss: 0.1185
Epoch [4/30], Step [500/903], Loss: 0.0240
Epoch [4/30], Step [550/903], Loss: 0.0138
Epoch [4/30], Step [600/903], Loss: 0.0178
Epoch [4/30], Step [650/903], Loss: 0.0617
Epoch [4/30], Step [700/903], Loss: 0.1014
Epoch [4/30], Step [750/903], Loss: 0.0475
Epoch [4/30], Step [800/903], Loss: 0.0539
Epoch [4/30], Step [850/903], Loss: 0.0473
Epoch [4/30], Step [900/903], Loss: 0.0639

Epoch [4/30] Summary:
Train Loss   : 0.0628
Train F1     : 0.8583
Train Recall : 0.9018
Train AUC    : 0.9908


Validation Evaluation:
Validation Loss   : 0.0897
Validation F1     : 0.2914
Validation Recall : 0.3929
Validation AUC    : 0.8897
[[3183   73]
 [  34   22]]
[INFO] Confusion matrix saved to: validation_confusion_matrix.png
