Training started at: 2025-05-09 01:19:42

Transform for label 0:
 Compose([
  Resize(p=1.0, height=256, interpolation=1, mask_interpolation=0, width=256),
  Normalize(p=1.0, max_pixel_value=255.0, mean=(0.5, 0.5, 0.5), normalization='standard', std=(0.5, 0.5, 0.5)),
  ToTensorV2(p=1.0, transpose_mask=False),
], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}, is_check_shapes=True)

Transform for label 1:
 Compose([
  ShiftScaleRotate(p=0.5, shift_limit_x=(-0.05, 0.05), shift_limit_y=(-0.05, 0.05), scale_limit=(-0.050000000000000044, 0.050000000000000044), rotate_limit=(-5.0, 5.0), interpolation=1, border_mode=2, fill=0.0, fill_mask=0.0, rotate_method='largest_box', mask_interpolation=0),
  OneOf([
    CLAHE(p=0.3, clip_limit=(1.0, 2.0), tile_grid_size=(8, 8)),
    RandomBrightnessContrast(p=0.3, brightness_by_max=True, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), ensure_safe_range=False),
    HueSaturationValue(p=0.3, hue_shift_limit=(-20.0, 20.0), sat_shift_limit=(-30.0, 30.0), val_shift_limit=(-20.0, 20.0)),
  ], p=1.0),
  Resize(p=1.0, height=256, interpolation=1, mask_interpolation=0, width=256),
  Normalize(p=1.0, max_pixel_value=255.0, mean=(0.5, 0.5, 0.5), normalization='standard', std=(0.5, 0.5, 0.5)),
  ToTensorV2(p=1.0, transpose_mask=False),
], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}, is_check_shapes=True)
Class 0 count: 32542
Class 1 count: 584
[INFO] Starting augmentation. Total original samples: 28157
Class 0 count: 27664
Class 1 count: 2958
Class 0 count: 27664
Class 1 count: 2958
Learning Rate      : 0.0001
Batch Size   : 32
Epochs : 30
Threashold : 0.5
Total Samples      : 35591
Training Samples   : 30622
Validation Samples : 3312
Testing Samples : 1657
Epoch [1/30], Step [50/957], Loss: 0.6142
Epoch [1/30], Step [100/957], Loss: 0.2967
Epoch [1/30], Step [150/957], Loss: 0.3416
Epoch [1/30], Step [200/957], Loss: 1.1481
Epoch [1/30], Step [250/957], Loss: 0.5027
Epoch [1/30], Step [300/957], Loss: 0.3570
Epoch [1/30], Step [350/957], Loss: 0.5983
Epoch [1/30], Step [400/957], Loss: 0.5678
Epoch [1/30], Step [450/957], Loss: 0.5390
Epoch [1/30], Step [500/957], Loss: 0.1807
Epoch [1/30], Step [550/957], Loss: 0.2911
Epoch [1/30], Step [600/957], Loss: 0.4238
Epoch [1/30], Step [650/957], Loss: 0.1745
Epoch [1/30], Step [700/957], Loss: 0.4366
Epoch [1/30], Step [750/957], Loss: 0.4397
Epoch [1/30], Step [800/957], Loss: 0.1883
Epoch [1/30], Step [850/957], Loss: 0.2558
Epoch [1/30], Step [900/957], Loss: 0.2488
Epoch [1/30], Step [950/957], Loss: 0.2524

Epoch [1/30] Summary:
Train Loss   : 0.4399
Train F1     : 0.6067
Train Recall : 0.9067
Train AUC    : 0.9642


Validation Evaluation:
Validation Loss   : 0.4317
Validation F1     : 0.1558
Validation Recall : 0.5968
Validation AUC    : 0.8677
[[2874  376]
 [  25   37]]
[INFO] Confusion matrix saved to: validation_confusion_matrix.png
Epoch [2/30], Step [50/957], Loss: 0.0826
Epoch [2/30], Step [100/957], Loss: 0.2172
Epoch [2/30], Step [150/957], Loss: 0.8129
Epoch [2/30], Step [200/957], Loss: 0.2742
Epoch [2/30], Step [250/957], Loss: 0.5319
Epoch [2/30], Step [300/957], Loss: 0.0783
Epoch [2/30], Step [350/957], Loss: 0.2330
Epoch [2/30], Step [400/957], Loss: 0.2462
Epoch [2/30], Step [450/957], Loss: 0.2616
Epoch [2/30], Step [500/957], Loss: 0.1045
Epoch [2/30], Step [550/957], Loss: 0.3234
Epoch [2/30], Step [600/957], Loss: 0.3640
Epoch [2/30], Step [650/957], Loss: 0.1085
Epoch [2/30], Step [700/957], Loss: 0.2050
Epoch [2/30], Step [750/957], Loss: 0.1607
Epoch [2/30], Step [800/957], Loss: 0.1082
Epoch [2/30], Step [850/957], Loss: 0.2492
Epoch [2/30], Step [900/957], Loss: 0.0859
Epoch [2/30], Step [950/957], Loss: 0.2028

Epoch [2/30] Summary:
Train Loss   : 0.2997
Train F1     : 0.7169
Train Recall : 0.9327
Train AUC    : 0.9834


Validation Evaluation:
Validation Loss   : 0.4905
Validation F1     : 0.1176
Validation Recall : 0.4516
Validation AUC    : 0.8053
[[2864  386]
 [  34   28]]
[INFO] Confusion matrix saved to: validation_confusion_matrix.png
