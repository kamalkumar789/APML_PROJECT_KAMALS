Training started at: 2025-05-08 15:32:57

Transform for label 0:
 Compose([
  Resize(p=1.0, height=256, interpolation=1, mask_interpolation=0, width=256),
  Normalize(p=1.0, max_pixel_value=255.0, mean=(0.5, 0.5, 0.5), normalization='standard', std=(0.5, 0.5, 0.5)),
  ToTensorV2(p=1.0, transpose_mask=False),
], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}, is_check_shapes=True)

Transform for label 1:
 Compose([
  ShiftScaleRotate(p=0.5, shift_limit_x=(-0.05, 0.05), shift_limit_y=(-0.05, 0.05), scale_limit=(-0.050000000000000044, 0.050000000000000044), rotate_limit=(-5.0, 5.0), interpolation=1, border_mode=2, fill=0.0, fill_mask=0.0, rotate_method='largest_box', mask_interpolation=0),
  OneOf([
    CLAHE(p=0.3, clip_limit=(1.0, 2.0), tile_grid_size=(8, 8)),
    RandomBrightnessContrast(p=0.3, brightness_by_max=True, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), ensure_safe_range=False),
    HueSaturationValue(p=0.3, hue_shift_limit=(-20.0, 20.0), sat_shift_limit=(-30.0, 30.0), val_shift_limit=(-20.0, 20.0)),
  ], p=1.0),
  Resize(p=1.0, height=256, interpolation=1, mask_interpolation=0, width=256),
  Normalize(p=1.0, max_pixel_value=255.0, mean=(0.5, 0.5, 0.5), normalization='standard', std=(0.5, 0.5, 0.5)),
  ToTensorV2(p=1.0, transpose_mask=False),
], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}, is_check_shapes=True)
Class 0 count: 99
Class 1 count: 1
[INFO] Starting augmentation. Total original samples: 80
[INFO] Dataset type: <class 'torch.utils.data.dataset.Subset'>
[INFO] Original + augmented data type: <class 'list'>
[INFO] Final data length: 80
[INFO] Final dataset length: 80
[DEBUG] Sample image type: <class 'PIL.Image.Image'>
[INFO] Printing shapes of all images in subset_dataset:
Image 0 type: <class 'PIL.Image.Image'>
Image 1 type: <class 'PIL.Image.Image'>
Image 2 type: <class 'PIL.Image.Image'>
Image 3 type: <class 'PIL.Image.Image'>
Image 4 type: <class 'PIL.Image.Image'>
Image 5 type: <class 'PIL.Image.Image'>
Image 6 type: <class 'PIL.Image.Image'>
Image 7 type: <class 'PIL.Image.Image'>
Image 8 type: <class 'PIL.Image.Image'>
Image 9 type: <class 'PIL.Image.Image'>
Image 10 type: <class 'PIL.Image.Image'>
Image 11 type: <class 'PIL.Image.Image'>
Image 12 type: <class 'PIL.Image.Image'>
Image 13 type: <class 'PIL.Image.Image'>
Image 14 type: <class 'PIL.Image.Image'>
Image 15 type: <class 'PIL.Image.Image'>
Image 16 type: <class 'PIL.Image.Image'>
Image 17 type: <class 'PIL.Image.Image'>
Image 18 type: <class 'PIL.Image.Image'>
Image 19 type: <class 'PIL.Image.Image'>
Image 20 type: <class 'PIL.Image.Image'>
Image 21 type: <class 'PIL.Image.Image'>
Image 22 type: <class 'PIL.Image.Image'>
Image 23 type: <class 'PIL.Image.Image'>
Image 24 type: <class 'PIL.Image.Image'>
Image 25 type: <class 'PIL.Image.Image'>
Image 26 type: <class 'PIL.Image.Image'>
Image 27 type: <class 'PIL.Image.Image'>
Image 28 type: <class 'PIL.Image.Image'>
Image 29 type: <class 'PIL.Image.Image'>
Image 30 type: <class 'PIL.Image.Image'>
Image 31 type: <class 'PIL.Image.Image'>
Image 32 type: <class 'PIL.Image.Image'>
Image 33 type: <class 'PIL.Image.Image'>
Image 34 type: <class 'PIL.Image.Image'>
Image 35 type: <class 'PIL.Image.Image'>
Image 36 type: <class 'PIL.Image.Image'>
Image 37 type: <class 'PIL.Image.Image'>
Image 38 type: <class 'PIL.Image.Image'>
Image 39 type: <class 'PIL.Image.Image'>
Image 40 type: <class 'PIL.Image.Image'>
Image 41 type: <class 'PIL.Image.Image'>
Image 42 type: <class 'PIL.Image.Image'>
Image 43 type: <class 'PIL.Image.Image'>
Image 44 type: <class 'PIL.Image.Image'>
Image 45 type: <class 'PIL.Image.Image'>
Image 46 type: <class 'PIL.Image.Image'>
Image 47 type: <class 'PIL.Image.Image'>
Image 48 type: <class 'PIL.Image.Image'>
Image 49 type: <class 'PIL.Image.Image'>
Image 50 type: <class 'PIL.Image.Image'>
Image 51 type: <class 'PIL.Image.Image'>
Image 52 type: <class 'PIL.Image.Image'>
Image 53 type: <class 'PIL.Image.Image'>
Image 54 type: <class 'PIL.Image.Image'>
Image 55 type: <class 'PIL.Image.Image'>
Image 56 type: <class 'PIL.Image.Image'>
Image 57 type: <class 'PIL.Image.Image'>
Image 58 type: <class 'PIL.Image.Image'>
Image 59 type: <class 'PIL.Image.Image'>
Image 60 type: <class 'PIL.Image.Image'>
Image 61 type: <class 'PIL.Image.Image'>
Image 62 type: <class 'PIL.Image.Image'>
Image 63 type: <class 'PIL.Image.Image'>
Image 64 type: <class 'PIL.Image.Image'>
Image 65 type: <class 'PIL.Image.Image'>
Image 66 type: <class 'PIL.Image.Image'>
Image 67 type: <class 'PIL.Image.Image'>
Image 68 type: <class 'PIL.Image.Image'>
Image 69 type: <class 'PIL.Image.Image'>
Image 70 type: <class 'PIL.Image.Image'>
Image 71 type: <class 'PIL.Image.Image'>
Image 72 type: <class 'PIL.Image.Image'>
Image 73 type: <class 'PIL.Image.Image'>
Image 74 type: <class 'PIL.Image.Image'>
Image 75 type: <class 'PIL.Image.Image'>
Image 76 type: <class 'PIL.Image.Image'>
Image 77 type: <class 'PIL.Image.Image'>
Image 78 type: <class 'PIL.Image.Image'>
Image 79 type: <class 'PIL.Image.Image'>
80
Class 0 count: 80
Class 1 count: 0
80
Learning Rate      : 0.0001
Batch Size   : 32
Epochs : 10
Threashold : 0.5
Total Samples      : 100
Training Samples   : 80
Validation Samples : 10
Testing Samples : 10
Image shape before transform: torch.Size([32, 3, 256, 256])
Image shape before transform: torch.Size([32, 3, 256, 256])
Image shape before transform: torch.Size([16, 3, 256, 256])

Epoch [1/10] Summary:
Train Loss   : 0.3765
Train F1     : 0.0000
Train Recall : 0.0000
Train AUC    : nan


Validation Evaluation:
Validation Loss   : 0.3782
Validation F1     : 0.0000
Validation Recall : 0.0000
Validation AUC    : 0.6667
[[8 1]
 [1 0]]
[INFO] Confusion matrix saved to: validation_confusion_matrix.png
Image shape before transform: torch.Size([32, 3, 256, 256])
Image shape before transform: torch.Size([32, 3, 256, 256])
